{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refineDataSets(data, isTest):\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import math \n",
    "    \n",
    "    data = data.drop(['PassengerId', 'Ticket', 'Cabin', 'Fare'], axis=1)\n",
    "\n",
    "    for i in range(0, data.shape[0]):\n",
    "        if('Mr. ' in data['Name'][i]):\n",
    "            data['Name'][i] = 0\n",
    "            \n",
    "        elif('Misc. ' in data['Name'][i]):\n",
    "            data['Name'][i] = 1\n",
    "            \n",
    "        elif('Master. ' in data['Name'][i]):\n",
    "            data['Name'][i] = 2\n",
    "            \n",
    "        elif('Miss. ' in data['Name'][i]):\n",
    "            data['Name'][i] = 3\n",
    "            \n",
    "        elif('Mrs. ' in data['Name'][i]):\n",
    "            data['Name'][i] = 4\n",
    "            \n",
    "        else:\n",
    "            data['Name'][i] = 5\n",
    "            \n",
    "        if(data['Sex'][i] == 'female'):\n",
    "            data['Sex'][i] = 1\n",
    "        \n",
    "        else:\n",
    "            data['Sex'][i] = 0\n",
    "    \n",
    "        if(data['Embarked'][i] == 'S'):\n",
    "            data['Embarked'][i] = 0\n",
    "    \n",
    "        elif(data['Embarked'][i] == 'C'):\n",
    "            data['Embarked'][i] = 1\n",
    "    \n",
    "        else:\n",
    "            data['Embarked'][i] = 2\n",
    "            \n",
    "        if(math.isnan(data['Age'][i])):\n",
    "            data['Age'][i] = data['Age'].mean()\n",
    "            \n",
    "        if(math.isnan(data['Pclass'][i])):\n",
    "            data['Pclass'][i] = data['Pclass'].mean()\n",
    "            \n",
    "        if(math.isnan(data['SibSp'][i])):\n",
    "            data['SibSp'][i] = data['SibSp'].mean()\n",
    "    \n",
    "    \n",
    "    data['Embarked'][0] = 0\n",
    "    \n",
    "    x_data = data.values\n",
    "    x_data = np.float32(np.transpose(x_data))\n",
    "    \n",
    "    if not isTest:\n",
    "        x_data = np.delete(x_data, 0, 0)\n",
    "        \n",
    "    x_data = np.transpose(x_data)\n",
    "        \n",
    "    if isTest:\n",
    "        return x_data\n",
    "    \n",
    "    p_data = np.array([data['Survived'].values])\n",
    "    p_data = np.float32(np.transpose(p_data))\n",
    "    return x_data, p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \n",
    "    import tensorflow_probability as tfp\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tfp.layers.DenseFlipout(10, dtype=tf.float32))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tfp.layers.DenseFlipout(20, dtype=tf.float32))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tfp.layers.DenseFlipout(1, dtype=tf.float32, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x_train_data, p_train_data, model):\n",
    "    model.fit(x_train_data[:712], p_train_data[:712], validation_data=(x_train_data[:891], p_train_data[:891]), epochs=1000)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSurvival(x_test_data, model):\n",
    "    import numpy as np\n",
    "    return list(np.int32(np.round(model.predict(x_test_data)).reshape(-1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('/Users/krishnapaparaju/Downloads/train.csv')\n",
    "test_data = pd.read_csv('/Users/krishnapaparaju/Downloads/test.csv')\n",
    "\n",
    "x_train_data, p_train_data = refineDataSets(train_data, False)\n",
    "x_test_data = refineDataSets(test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 891 samples\n",
      "Epoch 1/1000\n",
      "712/712 [==============================] - 1s 1ms/step - loss: 731.6205 - val_loss: 727.8929\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 724.7293 - val_loss: 721.0883\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 717.9872 - val_loss: 714.3980\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 711.3341 - val_loss: 707.7842\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 704.7462 - val_loss: 701.2251\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 698.2048 - val_loss: 694.7012\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 691.6933 - val_loss: 688.2034\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 685.2094 - val_loss: 681.7313\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 678.7448 - val_loss: 675.2736\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 672.2912 - val_loss: 668.8291\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 665.8565 - val_loss: 662.4005\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 659.4316 - val_loss: 655.9790\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 653.0167 - val_loss: 649.5705\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 646.6105 - val_loss: 643.1686\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 640.2188 - val_loss: 636.7777\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 633.8284 - val_loss: 630.4008\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 627.4521 - val_loss: 624.0307\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 621.0903 - val_loss: 617.6717\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 614.7338 - val_loss: 611.3210\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 608.3904 - val_loss: 604.9845\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 602.0533 - val_loss: 598.6556\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 595.7314 - val_loss: 592.3327\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 589.4191 - val_loss: 586.0256\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 583.1138 - val_loss: 579.7311\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 576.8266 - val_loss: 573.4437\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 570.5437 - val_loss: 567.1717\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 567.149 - 0s 88us/step - loss: 564.2782 - val_loss: 560.9139\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 558.0209 - val_loss: 554.6627\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 551.7779 - val_loss: 548.4281\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 545.5539 - val_loss: 542.2016\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 539.3358 - val_loss: 535.9932\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 533.1227 - val_loss: 529.7888\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 526.9324 - val_loss: 523.6092\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 520.7594 - val_loss: 517.4458\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 514.6016 - val_loss: 511.2860\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 508.4392 - val_loss: 505.1395\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 502.3087 - val_loss: 499.0216\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 496.1905 - val_loss: 492.9142\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 490.0956 - val_loss: 486.8286\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 484.0131 - val_loss: 480.7524\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 477.9461 - val_loss: 474.6762\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 471.9026 - val_loss: 468.6412\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 465.8475 - val_loss: 462.6105\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 459.8483 - val_loss: 456.6020\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 453.8316 - val_loss: 450.6367\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 447.8762 - val_loss: 444.6718\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 441.9066 - val_loss: 438.7120\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 435.9802 - val_loss: 432.7885\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 430.0338 - val_loss: 426.8666\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 424.1692 - val_loss: 420.9719\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 418.2508 - val_loss: 415.1447\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 412.4236 - val_loss: 409.3343\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 406.6011 - val_loss: 403.4648\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 400.7548 - val_loss: 397.6566\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 395.0083 - val_loss: 391.8697\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 389.2973 - val_loss: 386.1265\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 383.4837 - val_loss: 380.4609\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 377.8240 - val_loss: 374.7526\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 372.1424 - val_loss: 369.0832\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 366.4279 - val_loss: 363.3802\n",
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 360.8080 - val_loss: 357.7520\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 355.2503 - val_loss: 352.2020\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 349.6243 - val_loss: 346.6591\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 344.1177 - val_loss: 341.1318\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 338.5791 - val_loss: 335.5691\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 333.1899 - val_loss: 330.1644\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 327.6223 - val_loss: 324.8123\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 322.2897 - val_loss: 319.3476\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 316.9803 - val_loss: 313.9978\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 311.4906 - val_loss: 308.6320\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 306.1844 - val_loss: 303.3793\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 300.9380 - val_loss: 298.1037\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 295.7141 - val_loss: 292.8238\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 290.5229 - val_loss: 287.5754\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 285.2814 - val_loss: 282.4094\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 75us/step - loss: 280.1187 - val_loss: 277.3741\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 275.0600 - val_loss: 272.4343\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 270.0143 - val_loss: 267.3507\n",
      "Epoch 79/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 264.9607 - val_loss: 262.4447\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 259.9821 - val_loss: 257.2858\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 255.1359 - val_loss: 252.5066\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 250.3153 - val_loss: 247.6476\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 245.2432 - val_loss: 242.7501\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 240.4035 - val_loss: 238.0015\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 235.7351 - val_loss: 233.2880\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 231.0327 - val_loss: 228.5278\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 226.7258 - val_loss: 223.9073\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 221.6386 - val_loss: 219.3270\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 217.2602 - val_loss: 214.8611\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 212.5656 - val_loss: 210.2514\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 207.9717 - val_loss: 205.8326\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 203.8669 - val_loss: 201.2705\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 199.3811 - val_loss: 197.0621\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 194.9299 - val_loss: 192.6615\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 190.9987 - val_loss: 188.6288\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 186.3376 - val_loss: 184.2765\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 182.2136 - val_loss: 179.7070\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 178.4908 - val_loss: 175.7183\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 173.8592 - val_loss: 171.7226\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 169.9969 - val_loss: 167.8698\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 166.0720 - val_loss: 164.1241\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 162.0687 - val_loss: 160.0545\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 158.3740 - val_loss: 156.0511\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 154.2886 - val_loss: 152.1231\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 150.4160 - val_loss: 148.4108\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 146.9364 - val_loss: 144.6026\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 143.0180 - val_loss: 141.3115\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 139.2649 - val_loss: 137.3891\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 136.1126 - val_loss: 134.0556\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 131.9413 - val_loss: 130.2240\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 128.9255 - val_loss: 127.0932\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 125.1825 - val_loss: 123.2993\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 122.1742 - val_loss: 120.1548\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 118.9924 - val_loss: 117.1690\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 115.5663 - val_loss: 113.7296\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 112.6287 - val_loss: 111.0052\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 109.5245 - val_loss: 107.6655\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 105.7138 - val_loss: 104.1386\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 103.4199 - val_loss: 101.4304\n",
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 100.5598 - val_loss: 98.6419\n",
      "Epoch 121/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 97.2011 - val_loss: 95.7539\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 94.4777 - val_loss: 92.9273\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 91.5712 - val_loss: 89.6119\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 88.8544 - val_loss: 86.9569\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 85.7092 - val_loss: 84.4401\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 83.5761 - val_loss: 82.1069\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 80.5894 - val_loss: 79.8723\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 78.6030 - val_loss: 76.5617\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 75.9192 - val_loss: 74.6439\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 73.1306 - val_loss: 71.8616\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 71.0427 - val_loss: 69.8046\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 68.5159 - val_loss: 67.4008\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 66.1606 - val_loss: 65.2288\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 64.2149 - val_loss: 62.9958\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 61.8634 - val_loss: 61.1619\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 59.8716 - val_loss: 58.6223\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 57.9900 - val_loss: 56.7892\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 55.9698 - val_loss: 54.5725\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 53.8066 - val_loss: 52.7240\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 51.7437 - val_loss: 51.0012\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 50.3346 - val_loss: 49.1032\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 48.9092 - val_loss: 47.7954\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 46.4265 - val_loss: 45.6493\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 45.7044 - val_loss: 44.3185\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 43.1665 - val_loss: 42.5250\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 41.6561 - val_loss: 41.6435\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 40.1217 - val_loss: 39.7491\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 38.8460 - val_loss: 38.1892\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 37.7307 - val_loss: 36.7187\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 36.2043 - val_loss: 35.0415\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 34.2880 - val_loss: 34.1462\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 76us/step - loss: 33.4637 - val_loss: 32.5122\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 31.9626 - val_loss: 31.7984\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 30.9714 - val_loss: 30.4928\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 29.6434 - val_loss: 29.6241\n",
      "Epoch 156/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 28.2789 - val_loss: 28.1293\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 27.6637 - val_loss: 27.1419\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 26.5606 - val_loss: 26.1244\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 25.8073 - val_loss: 25.0424\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 24.9302 - val_loss: 24.1032\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 23.2156 - val_loss: 23.3751\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 22.8502 - val_loss: 22.3308\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 21.7442 - val_loss: 21.5908\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 21.3363 - val_loss: 20.6408\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 21.2003 - val_loss: 19.7189\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 20.1614 - val_loss: 19.0268\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 19.0707 - val_loss: 18.8250\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 18.4520 - val_loss: 17.9882\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 18.2097 - val_loss: 17.3395\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 17.0533 - val_loss: 16.4960\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 16.5623 - val_loss: 16.0837\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 15.9298 - val_loss: 15.7664\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 15.8034 - val_loss: 15.3563\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 14.7058 - val_loss: 14.7467\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 14.9940 - val_loss: 14.4877\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 14.0022 - val_loss: 14.1003\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 13.4979 - val_loss: 13.3732\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 13.1607 - val_loss: 12.9334\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 12.8990 - val_loss: 12.5668\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 12.7989 - val_loss: 12.6920\n",
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 12.0827 - val_loss: 11.8463\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 11.9707 - val_loss: 11.5303\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 12.1074 - val_loss: 11.2312\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 11.5962 - val_loss: 10.6153\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 11.5490 - val_loss: 10.8386\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 10.2705 - val_loss: 10.7935\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 9.9787 - val_loss: 10.2830\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 10.5141 - val_loss: 10.3188\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 10.1950 - val_loss: 9.4637\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 9.6894 - val_loss: 9.6704\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 9.3608 - val_loss: 9.4442\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 9.2541 - val_loss: 9.1766\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 9.0270 - val_loss: 8.8839\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 9.5147 - val_loss: 9.1474\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 8.9814 - val_loss: 8.7492\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 8.6969 - val_loss: 8.7265\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 8.3761 - val_loss: 8.7674\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 8.2946 - val_loss: 8.3572\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 8.5794 - val_loss: 8.7606\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 8.4578 - val_loss: 8.5745\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 8.0079 - val_loss: 8.1970\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 8.1204 - val_loss: 8.0564\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 8.2781 - val_loss: 7.9262\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.9197 - val_loss: 8.0406\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.7764 - val_loss: 7.9250\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4647 - val_loss: 7.4395\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.5742 - val_loss: 7.6787\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.6145 - val_loss: 7.9546\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 8.1244 - val_loss: 7.5745\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 8.2654 - val_loss: 7.8951\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.0523 - val_loss: 7.8430\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.9147 - val_loss: 7.4301\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.1987 - val_loss: 7.5276\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.9588 - val_loss: 7.6833\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3245 - val_loss: 7.3460\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.5316 - val_loss: 7.3400\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.7909 - val_loss: 7.6215\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4308 - val_loss: 7.7795\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3113 - val_loss: 7.0024\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.5830 - val_loss: 6.9629\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1665 - val_loss: 7.3341\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.1823 - val_loss: 7.6231\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1603 - val_loss: 7.6719\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.5512 - val_loss: 7.2363\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.3003 - val_loss: 7.1141\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.4581 - val_loss: 7.5660\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.4785 - val_loss: 7.6383\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.4931 - val_loss: 7.2690\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 75us/step - loss: 7.5011 - val_loss: 7.7793\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.7968 - val_loss: 7.5663\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.4251 - val_loss: 7.4706\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.6612 - val_loss: 7.2577\n",
      "Epoch 233/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4332 - val_loss: 6.8244\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2394 - val_loss: 7.3289\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.9428 - val_loss: 7.3358\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.6162 - val_loss: 6.8951\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.2952 - val_loss: 7.1198\n",
      "Epoch 238/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4531 - val_loss: 7.4530\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 6.8498 - val_loss: 7.2955\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3523 - val_loss: 7.1389\n",
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.4603 - val_loss: 6.8831\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.5074 - val_loss: 7.2776\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.2679 - val_loss: 6.9578\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2778 - val_loss: 6.9576\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.2378 - val_loss: 7.4992\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1497 - val_loss: 7.0836\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2885 - val_loss: 7.2391\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.5901 - val_loss: 7.6853\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3688 - val_loss: 7.2969\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.2331 - val_loss: 7.0662\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 8.1674 - val_loss: 7.1611\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.2050 - val_loss: 7.1627\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.5172 - val_loss: 7.1974\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.1090 - val_loss: 6.8510\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.6354 - val_loss: 7.0671\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9587 - val_loss: 7.4368\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.4207 - val_loss: 7.0819\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9914 - val_loss: 7.0178\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 6.9016 - val_loss: 7.2019\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.3669 - val_loss: 7.6925\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1121 - val_loss: 7.3781\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.1414 - val_loss: 7.1483\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.5697 - val_loss: 7.4529\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.9368 - val_loss: 7.3586\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.0179 - val_loss: 7.1468\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.3485 - val_loss: 7.2524\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.8038 - val_loss: 7.2359\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.9439 - val_loss: 7.3952\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.8861 - val_loss: 7.4385\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3011 - val_loss: 7.0277\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.0003 - val_loss: 7.3466\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.8300 - val_loss: 7.1180\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4130 - val_loss: 7.4983\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9652 - val_loss: 7.1081\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1255 - val_loss: 7.2195\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.2720 - val_loss: 7.2863\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.2981 - val_loss: 7.2143\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.3489 - val_loss: 6.8635\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.4878 - val_loss: 7.5639\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.0280 - val_loss: 7.3463\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3434 - val_loss: 7.4113\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.2546 - val_loss: 6.9312\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.2812 - val_loss: 7.5505\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.0968 - val_loss: 7.1357\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1839 - val_loss: 7.4848\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.7907 - val_loss: 7.3313\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1196 - val_loss: 7.2823\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.2677 - val_loss: 7.0283\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.3609 - val_loss: 7.3966\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.3086 - val_loss: 7.6894\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.6568 - val_loss: 7.7877\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3104 - val_loss: 6.8528\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 7.1475 - val_loss: 7.6162\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 6.9477 - val_loss: 6.9405\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.6697 - val_loss: 7.0474\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 7.7068 - val_loss: 6.9272\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.3103 - val_loss: 7.4401\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.3752 - val_loss: 7.0579\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 6.8097 - val_loss: 6.9354\n",
      "Epoch 300/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 7.3469 - val_loss: 7.1342\n",
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.0316 - val_loss: 7.9427\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0170 - val_loss: 7.5578\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.2021 - val_loss: 7.1635\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3166 - val_loss: 7.0546\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2074 - val_loss: 7.3735\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 8.0835 - val_loss: 7.4124\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 85us/step - loss: 7.3792 - val_loss: 7.4480\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.1384 - val_loss: 7.2264\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2471 - val_loss: 7.3155\n",
      "Epoch 310/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4206 - val_loss: 7.3724\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.2099 - val_loss: 7.3742\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1157 - val_loss: 7.0299\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4612 - val_loss: 7.2405\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 7.1760 - val_loss: 7.0622\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 7.3338 - val_loss: 6.9312\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.0075 - val_loss: 7.1678\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.3253 - val_loss: 7.1892\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.4432 - val_loss: 7.0498\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.8353 - val_loss: 6.9447\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.3632 - val_loss: 6.9528\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.8972 - val_loss: 7.2415\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.1473 - val_loss: 7.1921\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.0459 - val_loss: 7.2176\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.5934 - val_loss: 7.1576\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 7.3125 - val_loss: 7.2726\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 7.2100 - val_loss: 7.2078\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3907 - val_loss: 7.2524\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.2868 - val_loss: 7.2391\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1333 - val_loss: 7.1324\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.3564 - val_loss: 6.7822\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.1162 - val_loss: 7.5699\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.0150 - val_loss: 7.2266\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9479 - val_loss: 7.2410\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.6596 - val_loss: 7.6423\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 8.1108 - val_loss: 7.5323\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.1973 - val_loss: 7.2688\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.4830 - val_loss: 7.0136\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.5685 - val_loss: 6.9837\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.7240 - val_loss: 6.9210\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 6.7741 - val_loss: 7.4870\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.6991 - val_loss: 7.7272\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.2393 - val_loss: 7.2411\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.8386 - val_loss: 7.3107\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.5070 - val_loss: 7.1083\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.1506 - val_loss: 7.2509\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.6931 - val_loss: 7.4171\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3966 - val_loss: 7.3612\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 6.9277 - val_loss: 7.4086\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.4418 - val_loss: 7.3582\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 6.9752 - val_loss: 7.1251\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3992 - val_loss: 7.2865\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.1865 - val_loss: 6.7108\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.7110 - val_loss: 7.2987\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 7.9856 - val_loss: 7.4841\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.5601 - val_loss: 7.3053\n",
      "Epoch 356/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 7.4806 - val_loss: 7.2719\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.5806 - val_loss: 7.4277\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 6.9243 - val_loss: 7.2248\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.0262 - val_loss: 7.5989\n",
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.8689 - val_loss: 7.3751\n",
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.1581 - val_loss: 7.1454\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.9702 - val_loss: 7.3583\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.7299 - val_loss: 7.7032\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.0829 - val_loss: 7.1456\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.3755 - val_loss: 7.5154\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.2172 - val_loss: 7.1165\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.4497 - val_loss: 7.3498\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.2474 - val_loss: 7.1607\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.9936 - val_loss: 7.3945\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 95us/step - loss: 7.6994 - val_loss: 7.6072\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3846 - val_loss: 7.1373\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 7.2776 - val_loss: 6.8612\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 7.1914 - val_loss: 7.4635\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.6309 - val_loss: 7.5061\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.3987 - val_loss: 7.0661\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.2341 - val_loss: 7.0495\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 7.0764 - val_loss: 7.3668\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.2581 - val_loss: 7.7017\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.2163 - val_loss: 7.4525\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1969 - val_loss: 7.4093\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 6.8545 - val_loss: 6.8194\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 6.9925 - val_loss: 7.3800\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2993 - val_loss: 7.2106\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.5267 - val_loss: 7.2628\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 88us/step - loss: 7.5956 - val_loss: 6.9130\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 7.5599 - val_loss: 7.3766\n",
      "Epoch 387/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.0273 - val_loss: 7.4237\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 7.3745 - val_loss: 7.1954\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.4680 - val_loss: 7.2202\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.5635 - val_loss: 7.1099\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.2822 - val_loss: 7.1473\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.4923 - val_loss: 7.5130\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.2418 - val_loss: 7.5589\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3954 - val_loss: 6.8783\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 6.6244 - val_loss: 6.8125\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4231 - val_loss: 7.3268\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.5172 - val_loss: 6.9797\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 7.3098 - val_loss: 7.3040\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.5456 - val_loss: 7.1647\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 6.9438 - val_loss: 7.1435\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.7120 - val_loss: 7.3872\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0788 - val_loss: 7.3247\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.5924 - val_loss: 7.4602\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.5390 - val_loss: 7.0497\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.3073 - val_loss: 7.2614\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5078 - val_loss: 7.1232\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.1889 - val_loss: 6.8386\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5576 - val_loss: 6.8953\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.6351 - val_loss: 7.2920\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.3336 - val_loss: 7.1575\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.2331 - val_loss: 7.0422\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.6921 - val_loss: 7.2019\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1224 - val_loss: 6.8386\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.7747 - val_loss: 7.0183\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.0647 - val_loss: 7.5012\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 7.3085 - val_loss: 7.1101\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0230 - val_loss: 7.3263\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9447 - val_loss: 7.8097\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.7784 - val_loss: 7.4600\n",
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.5308 - val_loss: 7.8989\n",
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3150 - val_loss: 6.9430\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5558 - val_loss: 7.2013\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5166 - val_loss: 6.8818\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.4033 - val_loss: 6.8396\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.6831 - val_loss: 7.5323\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.6966 - val_loss: 7.1816\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.6122 - val_loss: 7.1050\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.0364 - val_loss: 7.2556\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 6.9127 - val_loss: 7.4337\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.2120 - val_loss: 6.8999\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.4066 - val_loss: 7.3252\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0748 - val_loss: 7.2003\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.6408 - val_loss: 7.3855\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.3765 - val_loss: 7.0547\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.0421 - val_loss: 7.0542\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.4093 - val_loss: 6.9677\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0903 - val_loss: 7.3539\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.5128 - val_loss: 7.3000\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 6.6013 - val_loss: 7.4287\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 7.4270 - val_loss: 7.3164\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.6554 - val_loss: 7.0512\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.7515 - val_loss: 7.1271\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.1855 - val_loss: 7.2056\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.2009 - val_loss: 7.4752\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.2138 - val_loss: 7.0958\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 6.8712 - val_loss: 7.1999\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.7430 - val_loss: 6.8429\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 7.6241 - val_loss: 7.1753\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4556 - val_loss: 7.2076\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 5.817 - 0s 85us/step - loss: 7.1907 - val_loss: 7.0844\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3117 - val_loss: 7.4692\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.7366 - val_loss: 7.4269\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.3703 - val_loss: 7.3806\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.5496 - val_loss: 7.0837\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2049 - val_loss: 6.9074\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.7555 - val_loss: 7.1169\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.4768 - val_loss: 7.1516\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.2426 - val_loss: 7.2953\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.3930 - val_loss: 7.6585\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.7445 - val_loss: 6.9334\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.4253 - val_loss: 7.5096\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.2325 - val_loss: 7.1110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.4301 - val_loss: 7.3401\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3395 - val_loss: 6.9828\n",
      "Epoch 465/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.4511 - val_loss: 7.5155\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.0386 - val_loss: 7.0446\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 7.4009 - val_loss: 7.4726\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.6221 - val_loss: 7.3422\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.5221 - val_loss: 6.6719\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.4447 - val_loss: 7.4611\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 93us/step - loss: 7.3145 - val_loss: 7.8264\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 7.4837 - val_loss: 7.0585\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 6.8089 - val_loss: 7.4851\n",
      "Epoch 474/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.7203 - val_loss: 7.1157\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.5942 - val_loss: 7.4318\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.1799 - val_loss: 7.3054\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.1578 - val_loss: 6.9836\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2460 - val_loss: 6.8184\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4312 - val_loss: 6.9001\n",
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6496 - val_loss: 7.2037\n",
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4984 - val_loss: 7.2808\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3189 - val_loss: 7.2033\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0174 - val_loss: 7.0871\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.0243 - val_loss: 7.3860\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.7672 - val_loss: 7.1652\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.6322 - val_loss: 7.0290\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 6.8492 - val_loss: 6.8073\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3083 - val_loss: 7.3799\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 6.9073 - val_loss: 7.1446\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.6801 - val_loss: 7.3788\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.1023 - val_loss: 7.3375\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.9100 - val_loss: 7.1347\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0511 - val_loss: 7.4444\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.5853 - val_loss: 6.9938\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0305 - val_loss: 7.7400\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1659 - val_loss: 7.2815\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.7887 - val_loss: 7.6518\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1433 - val_loss: 7.2922\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.5875 - val_loss: 7.4438\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.7235 - val_loss: 7.5380\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2393 - val_loss: 7.3246\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5396 - val_loss: 7.2283\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 6.8085 - val_loss: 7.5443\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.8810 - val_loss: 7.1027\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.2820 - val_loss: 7.2296\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 8.2380 - val_loss: 7.4344\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4672 - val_loss: 6.9874\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.5011 - val_loss: 7.3445\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.4933 - val_loss: 7.2742\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.4281 - val_loss: 7.2993\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3594 - val_loss: 7.6362\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2324 - val_loss: 7.2681\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.2375 - val_loss: 7.2905\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.9025 - val_loss: 7.3534\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1706 - val_loss: 7.1606\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.9009 - val_loss: 7.0059\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1667 - val_loss: 7.3195\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.5552 - val_loss: 7.5376\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.2432 - val_loss: 7.5884\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3121 - val_loss: 7.1534\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.4613 - val_loss: 7.3519\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.8774 - val_loss: 7.3805\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.8685 - val_loss: 6.7146\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.4813 - val_loss: 7.1441\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.4728 - val_loss: 7.0867\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.9748 - val_loss: 7.3039\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.7111 - val_loss: 7.2098\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3111 - val_loss: 7.4960\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.9442 - val_loss: 6.9267\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.3308 - val_loss: 6.9318\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.5581 - val_loss: 7.4581\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4372 - val_loss: 7.1056\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1051 - val_loss: 7.5905\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1092 - val_loss: 7.2486\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.8595 - val_loss: 7.1864\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1433 - val_loss: 6.9616\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.4907 - val_loss: 7.5091\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1778 - val_loss: 7.8593\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1498 - val_loss: 7.3186\n",
      "Epoch 540/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.8120 - val_loss: 7.3272\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 75us/step - loss: 7.7188 - val_loss: 7.5211\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.5362 - val_loss: 7.4513\n",
      "Epoch 543/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2860 - val_loss: 7.1283\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3624 - val_loss: 6.7736\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4924 - val_loss: 6.5604\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.7042 - val_loss: 7.3207\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.7856 - val_loss: 7.2731\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1039 - val_loss: 7.4385\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5927 - val_loss: 7.0247\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.2111 - val_loss: 6.6772\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.1018 - val_loss: 7.2962\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9903 - val_loss: 6.8436\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0052 - val_loss: 7.5634\n",
      "Epoch 554/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.3688 - val_loss: 7.1218\n",
      "Epoch 555/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3001 - val_loss: 7.0651\n",
      "Epoch 556/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3486 - val_loss: 7.1159\n",
      "Epoch 557/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.7070 - val_loss: 7.0395\n",
      "Epoch 558/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.6604 - val_loss: 7.5120\n",
      "Epoch 559/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.5281 - val_loss: 7.0652\n",
      "Epoch 560/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 6.9774 - val_loss: 7.2108\n",
      "Epoch 561/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1293 - val_loss: 6.9920\n",
      "Epoch 562/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.2202 - val_loss: 7.4368\n",
      "Epoch 563/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.1666 - val_loss: 6.8821\n",
      "Epoch 564/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.6881 - val_loss: 7.6341\n",
      "Epoch 565/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.1972 - val_loss: 7.2138\n",
      "Epoch 566/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 6.6020 - val_loss: 7.2366\n",
      "Epoch 567/1000\n",
      "712/712 [==============================] - 0s 165us/step - loss: 7.3006 - val_loss: 7.4015\n",
      "Epoch 568/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 6.9973 - val_loss: 7.3058\n",
      "Epoch 569/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.7744 - val_loss: 7.2816\n",
      "Epoch 570/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.3083 - val_loss: 7.2984\n",
      "Epoch 571/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.5695 - val_loss: 6.9507\n",
      "Epoch 572/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.4133 - val_loss: 7.4831\n",
      "Epoch 573/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 6.7940 - val_loss: 7.0887\n",
      "Epoch 574/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.0967 - val_loss: 7.1830\n",
      "Epoch 575/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.2721 - val_loss: 7.3074\n",
      "Epoch 576/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.0677 - val_loss: 7.1773\n",
      "Epoch 577/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 6.8096 - val_loss: 6.9675\n",
      "Epoch 578/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.3773 - val_loss: 7.1642\n",
      "Epoch 579/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.1206 - val_loss: 6.7647\n",
      "Epoch 580/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 6.9599 - val_loss: 7.2603\n",
      "Epoch 581/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.4643 - val_loss: 7.0903\n",
      "Epoch 582/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.4272 - val_loss: 7.6601\n",
      "Epoch 583/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1323 - val_loss: 7.0373\n",
      "Epoch 584/1000\n",
      "712/712 [==============================] - 0s 87us/step - loss: 7.0029 - val_loss: 7.0209\n",
      "Epoch 585/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.0366 - val_loss: 7.2849\n",
      "Epoch 586/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 6.9592 - val_loss: 7.2811\n",
      "Epoch 587/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.5023 - val_loss: 7.3626\n",
      "Epoch 588/1000\n",
      "712/712 [==============================] - 0s 86us/step - loss: 7.0748 - val_loss: 7.5791\n",
      "Epoch 589/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.4757 - val_loss: 7.0303\n",
      "Epoch 590/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.3873 - val_loss: 6.9858\n",
      "Epoch 591/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.7033 - val_loss: 7.7489\n",
      "Epoch 592/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.3627 - val_loss: 7.1923\n",
      "Epoch 593/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.7829 - val_loss: 6.7631\n",
      "Epoch 594/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 6.5344 - val_loss: 7.3985\n",
      "Epoch 595/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.1951 - val_loss: 7.3354\n",
      "Epoch 596/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.5456 - val_loss: 7.2942\n",
      "Epoch 597/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 7.3554 - val_loss: 7.4063\n",
      "Epoch 598/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 6.6263 - val_loss: 7.6902\n",
      "Epoch 599/1000\n",
      "712/712 [==============================] - 0s 83us/step - loss: 7.0847 - val_loss: 7.5065\n",
      "Epoch 600/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.3254 - val_loss: 6.6220\n",
      "Epoch 601/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3634 - val_loss: 6.9725\n",
      "Epoch 602/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.4488 - val_loss: 7.4247\n",
      "Epoch 603/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1839 - val_loss: 7.5290\n",
      "Epoch 604/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.3681 - val_loss: 7.1017\n",
      "Epoch 605/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.6201 - val_loss: 7.2566\n",
      "Epoch 606/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0564 - val_loss: 7.5819\n",
      "Epoch 607/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.5806 - val_loss: 7.7484\n",
      "Epoch 608/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.4568 - val_loss: 7.5535\n",
      "Epoch 609/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2536 - val_loss: 7.2319\n",
      "Epoch 610/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.6262 - val_loss: 7.5741\n",
      "Epoch 611/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1677 - val_loss: 7.0064\n",
      "Epoch 612/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.1196 - val_loss: 7.5947\n",
      "Epoch 613/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.1620 - val_loss: 7.0709\n",
      "Epoch 614/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9591 - val_loss: 7.0900\n",
      "Epoch 615/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9219 - val_loss: 7.3510\n",
      "Epoch 616/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.2684 - val_loss: 7.0741\n",
      "Epoch 617/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.2932 - val_loss: 6.7815\n",
      "Epoch 618/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3587 - val_loss: 6.9502\n",
      "Epoch 619/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 77us/step - loss: 7.3589 - val_loss: 6.9103\n",
      "Epoch 620/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.5117 - val_loss: 7.1407\n",
      "Epoch 621/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4195 - val_loss: 7.0326\n",
      "Epoch 622/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2264 - val_loss: 7.5584\n",
      "Epoch 623/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.3835 - val_loss: 6.7338\n",
      "Epoch 624/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.2811 - val_loss: 7.0302\n",
      "Epoch 625/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0101 - val_loss: 7.3766\n",
      "Epoch 626/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.8248 - val_loss: 7.7194\n",
      "Epoch 627/1000\n",
      "712/712 [==============================] - 0s 81us/step - loss: 7.2349 - val_loss: 7.3150\n",
      "Epoch 628/1000\n",
      "712/712 [==============================] - 0s 85us/step - loss: 7.5152 - val_loss: 7.0290\n",
      "Epoch 629/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.0181 - val_loss: 7.5581\n",
      "Epoch 630/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 7.0261 - val_loss: 6.8347\n",
      "Epoch 631/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 6.9832 - val_loss: 6.9378\n",
      "Epoch 632/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.5989 - val_loss: 7.4257\n",
      "Epoch 633/1000\n",
      "712/712 [==============================] - 0s 82us/step - loss: 7.5378 - val_loss: 7.4801\n",
      "Epoch 634/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3371 - val_loss: 7.1259\n",
      "Epoch 635/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.2803 - val_loss: 7.0299\n",
      "Epoch 636/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.6940 - val_loss: 7.4528\n",
      "Epoch 637/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.4216 - val_loss: 6.9786\n",
      "Epoch 638/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3194 - val_loss: 7.2866\n",
      "Epoch 639/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4231 - val_loss: 7.2468\n",
      "Epoch 640/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.4626 - val_loss: 7.2800\n",
      "Epoch 641/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.8033 - val_loss: 6.9265\n",
      "Epoch 642/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 6.8215 - val_loss: 6.8327\n",
      "Epoch 643/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.6382 - val_loss: 7.2044\n",
      "Epoch 644/1000\n",
      "712/712 [==============================] - 0s 89us/step - loss: 7.4699 - val_loss: 7.4906\n",
      "Epoch 645/1000\n",
      "712/712 [==============================] - 0s 88us/step - loss: 7.0404 - val_loss: 7.6056\n",
      "Epoch 646/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.8441 - val_loss: 7.2046\n",
      "Epoch 647/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.0114 - val_loss: 7.4272\n",
      "Epoch 648/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.0626 - val_loss: 7.3102\n",
      "Epoch 649/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.5015 - val_loss: 7.2377\n",
      "Epoch 650/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1793 - val_loss: 7.0890\n",
      "Epoch 651/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1069 - val_loss: 7.0353\n",
      "Epoch 652/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4323 - val_loss: 7.3152\n",
      "Epoch 653/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0553 - val_loss: 7.0111\n",
      "Epoch 654/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5833 - val_loss: 7.4504\n",
      "Epoch 655/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4664 - val_loss: 7.0466\n",
      "Epoch 656/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.0173 - val_loss: 7.1052\n",
      "Epoch 657/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2277 - val_loss: 7.0587\n",
      "Epoch 658/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3453 - val_loss: 7.2255\n",
      "Epoch 659/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4329 - val_loss: 7.1523\n",
      "Epoch 660/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1655 - val_loss: 7.5492\n",
      "Epoch 661/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5272 - val_loss: 7.3545\n",
      "Epoch 662/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3716 - val_loss: 6.9325\n",
      "Epoch 663/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.4695 - val_loss: 7.2464\n",
      "Epoch 664/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.8712 - val_loss: 8.0063\n",
      "Epoch 665/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.5487 - val_loss: 7.4640\n",
      "Epoch 666/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3497 - val_loss: 6.7596\n",
      "Epoch 667/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0002 - val_loss: 7.3781\n",
      "Epoch 668/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0705 - val_loss: 7.3161\n",
      "Epoch 669/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6952 - val_loss: 7.4305\n",
      "Epoch 670/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2978 - val_loss: 7.4117\n",
      "Epoch 671/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1952 - val_loss: 7.6032\n",
      "Epoch 672/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7473 - val_loss: 7.2986\n",
      "Epoch 673/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.0320 - val_loss: 6.8391\n",
      "Epoch 674/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.0090 - val_loss: 7.2282\n",
      "Epoch 675/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.2752 - val_loss: 7.4643\n",
      "Epoch 676/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1692 - val_loss: 7.2750\n",
      "Epoch 677/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.8135 - val_loss: 7.4192\n",
      "Epoch 678/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4458 - val_loss: 6.8323\n",
      "Epoch 679/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3141 - val_loss: 7.2199\n",
      "Epoch 680/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0123 - val_loss: 7.3559\n",
      "Epoch 681/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6954 - val_loss: 7.6072\n",
      "Epoch 682/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0582 - val_loss: 7.1216\n",
      "Epoch 683/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1741 - val_loss: 7.4443\n",
      "Epoch 684/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.9922 - val_loss: 7.4360\n",
      "Epoch 685/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.1048 - val_loss: 7.6364\n",
      "Epoch 686/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.1959 - val_loss: 6.8543\n",
      "Epoch 687/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.7593 - val_loss: 7.2356\n",
      "Epoch 688/1000\n",
      "712/712 [==============================] - 0s 79us/step - loss: 7.3790 - val_loss: 6.8415\n",
      "Epoch 689/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0620 - val_loss: 6.8664\n",
      "Epoch 690/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3410 - val_loss: 7.2993\n",
      "Epoch 691/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3169 - val_loss: 7.2491\n",
      "Epoch 692/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.8769 - val_loss: 7.1921\n",
      "Epoch 693/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6428 - val_loss: 7.4326\n",
      "Epoch 694/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4119 - val_loss: 6.9563\n",
      "Epoch 695/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.6155 - val_loss: 7.5162\n",
      "Epoch 696/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4321 - val_loss: 6.8297\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 71us/step - loss: 7.0641 - val_loss: 6.9565\n",
      "Epoch 698/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2726 - val_loss: 7.0405\n",
      "Epoch 699/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2982 - val_loss: 7.3773\n",
      "Epoch 700/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9242 - val_loss: 7.2037\n",
      "Epoch 701/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1376 - val_loss: 7.2836\n",
      "Epoch 702/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0125 - val_loss: 7.2816\n",
      "Epoch 703/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1540 - val_loss: 7.3583\n",
      "Epoch 704/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3493 - val_loss: 7.0377\n",
      "Epoch 705/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4953 - val_loss: 7.1167\n",
      "Epoch 706/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4492 - val_loss: 7.4773\n",
      "Epoch 707/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6023 - val_loss: 6.9055\n",
      "Epoch 708/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3201 - val_loss: 7.2648\n",
      "Epoch 709/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0524 - val_loss: 7.2447\n",
      "Epoch 710/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2874 - val_loss: 7.4003\n",
      "Epoch 711/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5151 - val_loss: 7.2334\n",
      "Epoch 712/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.8507 - val_loss: 7.2818\n",
      "Epoch 713/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3457 - val_loss: 7.2733\n",
      "Epoch 714/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1417 - val_loss: 7.3137\n",
      "Epoch 715/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0313 - val_loss: 7.3736\n",
      "Epoch 716/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0761 - val_loss: 7.3369\n",
      "Epoch 717/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3448 - val_loss: 7.1089\n",
      "Epoch 718/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.4554 - val_loss: 7.2412\n",
      "Epoch 719/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9996 - val_loss: 7.3746\n",
      "Epoch 720/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2209 - val_loss: 7.4014\n",
      "Epoch 721/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9909 - val_loss: 7.3540\n",
      "Epoch 722/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3326 - val_loss: 6.8566\n",
      "Epoch 723/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1697 - val_loss: 6.9134\n",
      "Epoch 724/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9537 - val_loss: 7.4274\n",
      "Epoch 725/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5805 - val_loss: 7.4330\n",
      "Epoch 726/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5891 - val_loss: 6.8382\n",
      "Epoch 727/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4476 - val_loss: 7.4290\n",
      "Epoch 728/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.0826 - val_loss: 7.2011\n",
      "Epoch 729/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5525 - val_loss: 7.4812\n",
      "Epoch 730/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2246 - val_loss: 7.3681\n",
      "Epoch 731/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3311 - val_loss: 7.4803\n",
      "Epoch 732/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2325 - val_loss: 6.9183\n",
      "Epoch 733/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3776 - val_loss: 7.6551\n",
      "Epoch 734/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9677 - val_loss: 7.2919\n",
      "Epoch 735/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1579 - val_loss: 7.4745\n",
      "Epoch 736/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.6689 - val_loss: 7.0827\n",
      "Epoch 737/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2087 - val_loss: 7.0583\n",
      "Epoch 738/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.5517 - val_loss: 7.1793\n",
      "Epoch 739/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.8489 - val_loss: 7.5731\n",
      "Epoch 740/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2501 - val_loss: 6.9912\n",
      "Epoch 741/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1408 - val_loss: 7.0272\n",
      "Epoch 742/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4960 - val_loss: 7.3105\n",
      "Epoch 743/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.0096 - val_loss: 7.3821\n",
      "Epoch 744/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4425 - val_loss: 7.5265\n",
      "Epoch 745/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0778 - val_loss: 7.2835\n",
      "Epoch 746/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6150 - val_loss: 6.7830\n",
      "Epoch 747/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3455 - val_loss: 7.4143\n",
      "Epoch 748/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2175 - val_loss: 7.2013\n",
      "Epoch 749/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.5745 - val_loss: 7.0489\n",
      "Epoch 750/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.8829 - val_loss: 7.3656\n",
      "Epoch 751/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5273 - val_loss: 7.4094\n",
      "Epoch 752/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.0865 - val_loss: 6.8103\n",
      "Epoch 753/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0526 - val_loss: 7.4264\n",
      "Epoch 754/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5465 - val_loss: 7.4713\n",
      "Epoch 755/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7791 - val_loss: 7.6394\n",
      "Epoch 756/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3023 - val_loss: 7.2997\n",
      "Epoch 757/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1783 - val_loss: 7.0766\n",
      "Epoch 758/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3370 - val_loss: 7.0425\n",
      "Epoch 759/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1857 - val_loss: 7.4806\n",
      "Epoch 760/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6943 - val_loss: 7.2874\n",
      "Epoch 761/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3700 - val_loss: 7.2175\n",
      "Epoch 762/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0533 - val_loss: 6.9346\n",
      "Epoch 763/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1745 - val_loss: 7.5243\n",
      "Epoch 764/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3972 - val_loss: 7.2985\n",
      "Epoch 765/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9936 - val_loss: 7.3490\n",
      "Epoch 766/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1068 - val_loss: 7.2685\n",
      "Epoch 767/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4299 - val_loss: 7.4126\n",
      "Epoch 768/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4050 - val_loss: 7.2602\n",
      "Epoch 769/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9191 - val_loss: 7.3849\n",
      "Epoch 770/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.0467 - val_loss: 7.2982\n",
      "Epoch 771/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2712 - val_loss: 7.0980\n",
      "Epoch 772/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0079 - val_loss: 7.5247\n",
      "Epoch 773/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0607 - val_loss: 7.0818\n",
      "Epoch 774/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.4927 - val_loss: 7.6064\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 72us/step - loss: 6.9317 - val_loss: 7.6014\n",
      "Epoch 776/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.2685 - val_loss: 6.5683\n",
      "Epoch 777/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5043 - val_loss: 7.2289\n",
      "Epoch 778/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1256 - val_loss: 7.1914\n",
      "Epoch 779/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1782 - val_loss: 7.4357\n",
      "Epoch 780/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9925 - val_loss: 7.2628\n",
      "Epoch 781/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4420 - val_loss: 6.9102\n",
      "Epoch 782/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2149 - val_loss: 7.1492\n",
      "Epoch 783/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4185 - val_loss: 7.4116\n",
      "Epoch 784/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.8646 - val_loss: 6.9645\n",
      "Epoch 785/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.8295 - val_loss: 7.3692\n",
      "Epoch 786/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0454 - val_loss: 7.1623\n",
      "Epoch 787/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3883 - val_loss: 7.5156\n",
      "Epoch 788/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4937 - val_loss: 7.3387\n",
      "Epoch 789/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.2661 - val_loss: 7.1695\n",
      "Epoch 790/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7207 - val_loss: 7.0435\n",
      "Epoch 791/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4164 - val_loss: 7.3680\n",
      "Epoch 792/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2255 - val_loss: 7.0891\n",
      "Epoch 793/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1409 - val_loss: 7.2981\n",
      "Epoch 794/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2500 - val_loss: 6.9551\n",
      "Epoch 795/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.5608 - val_loss: 7.1051\n",
      "Epoch 796/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0096 - val_loss: 7.3303\n",
      "Epoch 797/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3099 - val_loss: 7.5325\n",
      "Epoch 798/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2336 - val_loss: 7.0191\n",
      "Epoch 799/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1258 - val_loss: 7.6034\n",
      "Epoch 800/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9682 - val_loss: 7.3408\n",
      "Epoch 801/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 6.7574 - val_loss: 7.6386\n",
      "Epoch 802/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 7.4103 - val_loss: 7.1380\n",
      "Epoch 803/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.5053 - val_loss: 7.0898\n",
      "Epoch 804/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9905 - val_loss: 7.0413\n",
      "Epoch 805/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 6.9390 - val_loss: 6.9858\n",
      "Epoch 806/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 7.0588 - val_loss: 7.3354\n",
      "Epoch 807/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9882 - val_loss: 6.9615\n",
      "Epoch 808/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3108 - val_loss: 7.2897\n",
      "Epoch 809/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3788 - val_loss: 7.2414\n",
      "Epoch 810/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1102 - val_loss: 7.2742\n",
      "Epoch 811/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7605 - val_loss: 7.1914\n",
      "Epoch 812/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1021 - val_loss: 7.2697\n",
      "Epoch 813/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.6925 - val_loss: 7.0436\n",
      "Epoch 814/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9343 - val_loss: 7.2310\n",
      "Epoch 815/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.6553 - val_loss: 7.4662\n",
      "Epoch 816/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7201 - val_loss: 7.3190\n",
      "Epoch 817/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2763 - val_loss: 7.3650\n",
      "Epoch 818/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0484 - val_loss: 6.9728\n",
      "Epoch 819/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.7513 - val_loss: 7.4213\n",
      "Epoch 820/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3800 - val_loss: 7.1512\n",
      "Epoch 821/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3514 - val_loss: 7.5505\n",
      "Epoch 822/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6868 - val_loss: 6.8231\n",
      "Epoch 823/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.2847 - val_loss: 7.1997\n",
      "Epoch 824/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.7555 - val_loss: 7.5635\n",
      "Epoch 825/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0089 - val_loss: 7.2659\n",
      "Epoch 826/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4924 - val_loss: 7.5034\n",
      "Epoch 827/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3823 - val_loss: 7.3810\n",
      "Epoch 828/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.1384 - val_loss: 7.2001\n",
      "Epoch 829/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3406 - val_loss: 7.1702\n",
      "Epoch 830/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.2080 - val_loss: 7.4220\n",
      "Epoch 831/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.8210 - val_loss: 7.3094\n",
      "Epoch 832/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4097 - val_loss: 7.2697\n",
      "Epoch 833/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5473 - val_loss: 7.5001\n",
      "Epoch 834/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.8934 - val_loss: 6.8150\n",
      "Epoch 835/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3726 - val_loss: 7.5055\n",
      "Epoch 836/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3711 - val_loss: 7.4324\n",
      "Epoch 837/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.4566 - val_loss: 6.7945\n",
      "Epoch 838/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9335 - val_loss: 6.8953\n",
      "Epoch 839/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9467 - val_loss: 7.5496\n",
      "Epoch 840/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3163 - val_loss: 7.3161\n",
      "Epoch 841/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9846 - val_loss: 7.3804\n",
      "Epoch 842/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.7005 - val_loss: 7.4687\n",
      "Epoch 843/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4779 - val_loss: 7.3560\n",
      "Epoch 844/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.5388 - val_loss: 7.2251\n",
      "Epoch 845/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.6972 - val_loss: 7.2438\n",
      "Epoch 846/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.5073 - val_loss: 7.4588\n",
      "Epoch 847/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.6945 - val_loss: 7.1856\n",
      "Epoch 848/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2444 - val_loss: 7.2611\n",
      "Epoch 849/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.7585 - val_loss: 7.8179\n",
      "Epoch 850/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.2220 - val_loss: 7.3534\n",
      "Epoch 851/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3480 - val_loss: 7.0695\n",
      "Epoch 852/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3161 - val_loss: 6.9942\n",
      "Epoch 853/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 69us/step - loss: 7.1977 - val_loss: 7.4597\n",
      "Epoch 854/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.5478 - val_loss: 7.6506\n",
      "Epoch 855/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4555 - val_loss: 7.1008\n",
      "Epoch 856/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0466 - val_loss: 7.0712\n",
      "Epoch 857/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.9819 - val_loss: 7.3453\n",
      "Epoch 858/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1690 - val_loss: 7.1868\n",
      "Epoch 859/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.9818 - val_loss: 7.2009\n",
      "Epoch 860/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.9589 - val_loss: 7.1947\n",
      "Epoch 861/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.5763 - val_loss: 7.0220\n",
      "Epoch 862/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1381 - val_loss: 7.0602\n",
      "Epoch 863/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.3984 - val_loss: 6.9787\n",
      "Epoch 864/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2993 - val_loss: 7.5056\n",
      "Epoch 865/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.4627 - val_loss: 7.3369\n",
      "Epoch 866/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.8043 - val_loss: 7.2322\n",
      "Epoch 867/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 7.0453 - val_loss: 7.5762\n",
      "Epoch 868/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.1643 - val_loss: 7.0816\n",
      "Epoch 869/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.1291 - val_loss: 7.0527\n",
      "Epoch 870/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3960 - val_loss: 7.4289\n",
      "Epoch 871/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4445 - val_loss: 7.3926\n",
      "Epoch 872/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2611 - val_loss: 7.3789\n",
      "Epoch 873/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4404 - val_loss: 7.3372\n",
      "Epoch 874/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.0610 - val_loss: 6.9024\n",
      "Epoch 875/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.9416 - val_loss: 6.8718\n",
      "Epoch 876/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4817 - val_loss: 7.2285\n",
      "Epoch 877/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0358 - val_loss: 7.2783\n",
      "Epoch 878/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3004 - val_loss: 7.2115\n",
      "Epoch 879/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1645 - val_loss: 7.3418\n",
      "Epoch 880/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3834 - val_loss: 7.4905\n",
      "Epoch 881/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0183 - val_loss: 7.1479\n",
      "Epoch 882/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1657 - val_loss: 7.0524\n",
      "Epoch 883/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.3683 - val_loss: 7.2849\n",
      "Epoch 884/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4252 - val_loss: 7.5973\n",
      "Epoch 885/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.5511 - val_loss: 7.5498\n",
      "Epoch 886/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.8767 - val_loss: 7.8083\n",
      "Epoch 887/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2677 - val_loss: 7.1266\n",
      "Epoch 888/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.2159 - val_loss: 6.9394\n",
      "Epoch 889/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.9400 - val_loss: 7.1388\n",
      "Epoch 890/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2608 - val_loss: 7.4993\n",
      "Epoch 891/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3519 - val_loss: 6.8777\n",
      "Epoch 892/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1730 - val_loss: 7.3462\n",
      "Epoch 893/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2348 - val_loss: 7.2550\n",
      "Epoch 894/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3459 - val_loss: 7.1172\n",
      "Epoch 895/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1121 - val_loss: 7.4367\n",
      "Epoch 896/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1771 - val_loss: 7.6560\n",
      "Epoch 897/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0052 - val_loss: 7.4868\n",
      "Epoch 898/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.1556 - val_loss: 7.2648\n",
      "Epoch 899/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5273 - val_loss: 7.0754\n",
      "Epoch 900/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6566 - val_loss: 7.3205\n",
      "Epoch 901/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.8798 - val_loss: 7.2080\n",
      "Epoch 902/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5954 - val_loss: 7.2112\n",
      "Epoch 903/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.0223 - val_loss: 6.9089\n",
      "Epoch 904/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4364 - val_loss: 7.5170\n",
      "Epoch 905/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2388 - val_loss: 7.0616\n",
      "Epoch 906/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4123 - val_loss: 7.2819\n",
      "Epoch 907/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.8722 - val_loss: 7.4194\n",
      "Epoch 908/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.1767 - val_loss: 7.3729\n",
      "Epoch 909/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.6398 - val_loss: 7.2119\n",
      "Epoch 910/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9869 - val_loss: 7.3021\n",
      "Epoch 911/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.3439 - val_loss: 7.2215\n",
      "Epoch 912/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1458 - val_loss: 6.8521\n",
      "Epoch 913/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.9731 - val_loss: 6.7629\n",
      "Epoch 914/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2441 - val_loss: 7.5900\n",
      "Epoch 915/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.6356 - val_loss: 7.2969\n",
      "Epoch 916/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9482 - val_loss: 7.1615\n",
      "Epoch 917/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.9125 - val_loss: 7.1145\n",
      "Epoch 918/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.9459 - val_loss: 7.1272\n",
      "Epoch 919/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9285 - val_loss: 6.9345\n",
      "Epoch 920/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.2067 - val_loss: 7.3345\n",
      "Epoch 921/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4276 - val_loss: 7.0341\n",
      "Epoch 922/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.8165 - val_loss: 7.1023\n",
      "Epoch 923/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.0881 - val_loss: 7.4110\n",
      "Epoch 924/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1152 - val_loss: 6.8870\n",
      "Epoch 925/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2424 - val_loss: 7.2248\n",
      "Epoch 926/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2181 - val_loss: 7.1918\n",
      "Epoch 927/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.9002 - val_loss: 7.4731\n",
      "Epoch 928/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.3208 - val_loss: 7.7489\n",
      "Epoch 929/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0279 - val_loss: 7.7827\n",
      "Epoch 930/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6240 - val_loss: 6.9205\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 77us/step - loss: 7.1486 - val_loss: 7.3676\n",
      "Epoch 932/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.0608 - val_loss: 7.2692\n",
      "Epoch 933/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 7.0451 - val_loss: 7.4544\n",
      "Epoch 934/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 6.9877 - val_loss: 7.1518\n",
      "Epoch 935/1000\n",
      "712/712 [==============================] - 0s 84us/step - loss: 6.8448 - val_loss: 7.5015\n",
      "Epoch 936/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 7.1803 - val_loss: 7.2326\n",
      "Epoch 937/1000\n",
      "712/712 [==============================] - 0s 80us/step - loss: 7.2045 - val_loss: 6.8923\n",
      "Epoch 938/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 6.9046 - val_loss: 6.5770\n",
      "Epoch 939/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.5948 - val_loss: 7.5016\n",
      "Epoch 940/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.5635 - val_loss: 7.3025\n",
      "Epoch 941/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.4283 - val_loss: 7.2483\n",
      "Epoch 942/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9586 - val_loss: 7.6133\n",
      "Epoch 943/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.4470 - val_loss: 7.1612\n",
      "Epoch 944/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2951 - val_loss: 7.2266\n",
      "Epoch 945/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2149 - val_loss: 7.0412\n",
      "Epoch 946/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.2501 - val_loss: 7.4084\n",
      "Epoch 947/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3758 - val_loss: 7.0708\n",
      "Epoch 948/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4977 - val_loss: 6.8721\n",
      "Epoch 949/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2996 - val_loss: 7.5097\n",
      "Epoch 950/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1273 - val_loss: 7.2989\n",
      "Epoch 951/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.8192 - val_loss: 7.0761\n",
      "Epoch 952/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9741 - val_loss: 7.4864\n",
      "Epoch 953/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2797 - val_loss: 7.0221\n",
      "Epoch 954/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0802 - val_loss: 7.1669\n",
      "Epoch 955/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.8611 - val_loss: 7.4190\n",
      "Epoch 956/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2077 - val_loss: 7.4724\n",
      "Epoch 957/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.7762 - val_loss: 7.0812\n",
      "Epoch 958/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.5697 - val_loss: 7.4644\n",
      "Epoch 959/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.1841 - val_loss: 6.5471\n",
      "Epoch 960/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9341 - val_loss: 6.8634\n",
      "Epoch 961/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3003 - val_loss: 7.2943\n",
      "Epoch 962/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0799 - val_loss: 7.2287\n",
      "Epoch 963/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4268 - val_loss: 7.0463\n",
      "Epoch 964/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2380 - val_loss: 7.3331\n",
      "Epoch 965/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.1722 - val_loss: 7.0318\n",
      "Epoch 966/1000\n",
      "712/712 [==============================] - 0s 74us/step - loss: 7.5062 - val_loss: 7.2068\n",
      "Epoch 967/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6647 - val_loss: 6.9598\n",
      "Epoch 968/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.1802 - val_loss: 7.0032\n",
      "Epoch 969/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0757 - val_loss: 7.6506\n",
      "Epoch 970/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3954 - val_loss: 7.5375\n",
      "Epoch 971/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.2530 - val_loss: 7.3880\n",
      "Epoch 972/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.9370 - val_loss: 7.0429\n",
      "Epoch 973/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.6118 - val_loss: 7.2658\n",
      "Epoch 974/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.1203 - val_loss: 7.1198\n",
      "Epoch 975/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9835 - val_loss: 7.8008\n",
      "Epoch 976/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 7.0360 - val_loss: 6.6279\n",
      "Epoch 977/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.5317 - val_loss: 6.6573\n",
      "Epoch 978/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 6.8119 - val_loss: 7.3486\n",
      "Epoch 979/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2966 - val_loss: 7.7064\n",
      "Epoch 980/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 6.8261 - val_loss: 6.9173\n",
      "Epoch 981/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.0303 - val_loss: 7.2279\n",
      "Epoch 982/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6041 - val_loss: 7.4062\n",
      "Epoch 983/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.8391 - val_loss: 7.1846\n",
      "Epoch 984/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.4936 - val_loss: 7.3519\n",
      "Epoch 985/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.7363 - val_loss: 6.8930\n",
      "Epoch 986/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.7714 - val_loss: 6.9683\n",
      "Epoch 987/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.9566 - val_loss: 7.3282\n",
      "Epoch 988/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.8543 - val_loss: 7.5086\n",
      "Epoch 989/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3580 - val_loss: 7.5791\n",
      "Epoch 990/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.4115 - val_loss: 7.0511\n",
      "Epoch 991/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.6303 - val_loss: 7.1091\n",
      "Epoch 992/1000\n",
      "712/712 [==============================] - 0s 69us/step - loss: 6.9462 - val_loss: 7.3200\n",
      "Epoch 993/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.2293 - val_loss: 7.0204\n",
      "Epoch 994/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 6.5643 - val_loss: 6.9367\n",
      "Epoch 995/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 6.6812 - val_loss: 7.3307\n",
      "Epoch 996/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.2023 - val_loss: 7.6167\n",
      "Epoch 997/1000\n",
      "712/712 [==============================] - 0s 73us/step - loss: 7.3629 - val_loss: 7.7958\n",
      "Epoch 998/1000\n",
      "712/712 [==============================] - 0s 72us/step - loss: 7.3429 - val_loss: 6.8667\n",
      "Epoch 999/1000\n",
      "712/712 [==============================] - 0s 70us/step - loss: 7.3579 - val_loss: 6.5509\n",
      "Epoch 1000/1000\n",
      "712/712 [==============================] - 0s 71us/step - loss: 7.0895 - val_loss: 7.3872\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "model = trainModel(x_train_data, p_train_data, model)\n",
    "predictions = predictSurvival(x_test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(test_data['PassengerId'].values)\n",
    "submission = pd.DataFrame(list(np.transpose([ids, predictions])))\n",
    "submission.columns = ['PassengerId', 'Survived']\n",
    "submission['PassengerId'] = np.int32(np.round(submission['PassengerId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         1\n",
       "1            893         0\n",
       "2            894         1\n",
       "3            895         0\n",
       "4            896         1\n",
       "5            897         1\n",
       "6            898         1\n",
       "7            899         1\n",
       "8            900         0\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         1\n",
       "14           906         0\n",
       "15           907         0\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         0\n",
       "19           911         0\n",
       "20           912         0\n",
       "21           913         1\n",
       "22           914         0\n",
       "23           915         1\n",
       "24           916         0\n",
       "25           917         1\n",
       "26           918         1\n",
       "27           919         1\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         1\n",
       "389         1281         0\n",
       "390         1282         1\n",
       "391         1283         1\n",
       "392         1284         1\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         0\n",
       "398         1290         1\n",
       "399         1291         0\n",
       "400         1292         0\n",
       "401         1293         0\n",
       "402         1294         0\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         1\n",
       "408         1300         0\n",
       "409         1301         1\n",
       "410         1302         0\n",
       "411         1303         1\n",
       "412         1304         1\n",
       "413         1305         0\n",
       "414         1306         0\n",
       "415         1307         1\n",
       "416         1308         1\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
